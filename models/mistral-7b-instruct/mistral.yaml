experiment:
  name: mistral-7b-instruct

model:
  model: mistral-7b-instruct
  type: pretrained_decoder

seed: 22

inference:
  max_length: 32768
  window:
    type: full
  tokenizer: file(../../configs/tokenizers/mistral.yaml)
  eos_token: </s>
  chat_template: file(../../configs/chat_templates/mistral.yaml)
