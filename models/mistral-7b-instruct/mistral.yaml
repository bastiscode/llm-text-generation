experiment:
  name: mistral-7b-instruct
input_tokenizer:
  tokenize:
    type: huggingface
    path: relpath(mistral/tokenizer.json)
  special:
    tokens:
      - <unk>
    pad: <unk>
  eos_token: </s>
chat_template:
  user: "[INST] {text} [/INST]"
  assistant: "{text}</s> "
model:
  name: mistral-7b-instruct
  type: pretrained_decoder
seed: 22
train:
  precision: bfp16
  data:
    max_length: 8192
