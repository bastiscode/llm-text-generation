experiment:
  name: mixtral-8x22b

model:
  model: mixtral-8x22b
  type: pretrained_decoder
  attn_implementation: env(ATTN_IMPLEMENTATION:null)
  load_in_4bit: env(4BIT:true)
  device_map: auto

seed: 22

inference:
  max_length: 65536
  window:
    type: full
  tokenizer: file(../../configs/tokenizers/mistral.yaml)
  eos: </s>
