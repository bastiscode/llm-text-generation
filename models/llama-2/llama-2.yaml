experiment:
  name: env(MODEL:llama-2-7b)

model:
  model: env(MODEL:llama-2-7b)
  type: pretrained_decoder

seed: 22

inference:
  max_length: 4096
  window:
    type: full
  tokenizer: file(../../configs/tokenizers/llama-2.yaml)
  eos_token: </s>
